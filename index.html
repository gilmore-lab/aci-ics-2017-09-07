<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Rick O. Gilmore" />
  <title>Reproducibility in Computationally-Intensive Behavioral Research</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/reveal.css"/>



<link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/theme/simple.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>


<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

    <script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
    <script src="libs/viz-0.3/viz.js"></script>
    <link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
    <script src="libs/grViz-binding-0.9.2/grViz.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Reproducibility in Computationally-Intensive Behavioral Research</h1>
    <h2 class="author">Rick O. Gilmore</h2>
    <h3 class="date">2017-09-07 12:35:00</h3>
</section>

<section><section id="preliminaries" class="titleslide slide level1"><h1>Preliminaries</h1></section><section class="slide level2">

<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/87/NSF_Logo.PNG" height=250px> <img src="https://science.nichd.nih.gov/confluence/download/attachments/34472103/NICHD-vertical-2-color.png?version=1&modificationDate=1477410070000&api=v2" height=250px> </br> <img src="https://sloan.org/storage/app/media/Logos/Sloan-Logo-stacked-black-web.png" height-250px></p>
<aside class="notes">
<p>I thank NSF, NICHD, SRCD, and the Sloan Foundation for support.</p>
</aside>
</section><section id="overview" class="slide level2">
<h1>Overview</h1>
<ul>
<li>The reproducibility “crisis”</li>
<li>The “crisis”&quot; in psychology</li>
<li>“Big data” behavioral science is computationally intensive</li>
<li>Let’s not waste a “good” crisis</li>
</ul>
</section></section>
<section><section id="the-reproducibility-crisis" class="titleslide slide level1"><h1>The reproducibility “crisis”</h1></section><section id="is-there-a-reproducibility-crisis" class="slide level2">
<h1>Is there a reproducibility crisis?</h1>
<ul>
<li class="fragment">Yes, a significant crisis</li>
<li class="fragment">Yes, a slight crisis</li>
<li class="fragment">No crisis</li>
<li class="fragment">Don’t know</li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://www.nature.com/polopoly_fs/7.36716.1469695923!/image/reproducibility-graphic-online1.jpeg_gen/derivatives/landscape_630/reproducibility-graphic-online1.jpeg" height=550px> </br> <small> (<a href="http://doi.org/10.1038/533452a">Baker, 2016</a>) </small></p>
</div>
<aside class="notes">
<p>Nature conducted a survey of some 1,600 scientists in 2016. They were asked this question and a few others. Here are the results.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://www.nature.com/polopoly_fs/7.36718.1464174471!/image/reproducibility-graphic-online3.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online3.jpg"" height=600px> </br> <small>(<a href="http://doi.org/10.1038/533452a">Baker, 2016</a>)</small></p>
</div>
<aside class="notes">

</aside>
</section><section id="what-does-reproducibility-mean" class="slide level2">
<h1>What does “reproducibility” mean?</h1>
<!-- --- -->
<!-- Should a published study contain sufficient information for an independent expert to reproduce the reported findings without consultation with or assistance from the original authors? -->
</section><section id="methods-reproducibility" class="slide level2">
<h1><em>Methods</em> reproducibility</h1>
<ul>
<li>Enough details about materials &amp; methods recorded (&amp; reported)</li>
<li>Same results with same materials &amp; methods</li>
</ul>
<p><small>(<a href="http://doi.org/10.1126/scitranslmed.aaf5027">Goodman et al., 2016</a>)</small></p>
<aside class="notes">
<p>Goodman et al. advocate a new lexicon for reproducibility where…</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://lh6.ggpht.com/_KVa1Tk_k1BU/TTjL-RSY_eI/AAAAAAAABtg/VQIfae1_wtQ/hit_thumb%5B3%5D.jpg?imgmax=800" height=550></p>
</div>
<aside class="notes">
<p>I like to call this the “hit by a truck” scenario.</p>
</aside>
</section><section id="results-reproducibility" class="slide level2">
<h1><em>Results</em> reproducibility</h1>
<ul>
<li>Same results from independent study</li>
</ul>
<p><small>(<a href="http://doi.org/10.1126/scitranslmed.aaf5027">Goodman et al., 2016</a>)</small></p>
<aside class="notes">
<p>Goodman et al. advocate a new lexicon for reproducibility where…</p>
</aside>
</section><section id="inferential-reproducibility" class="slide level2">
<h1><em>Inferential</em> reproducibility</h1>
<ul>
<li>Same inferences from one or more studies or reanalyses</li>
</ul>
<p><small>(<a href="http://doi.org/10.1126/scitranslmed.aaf5027">Goodman et al., 2016</a>)</small></p>
<aside class="notes">
<p>Goodman et al. advocate a new lexicon for reproducibility where…</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://www.nature.com/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg" height=600px> </br> <small>(<a href="http://doi.org/10.1038/533452a">Baker, 2016</a>)</small></p>
</div>
<aside class="notes">
<p>These definitions help put some of the presumed causes into perspective.</p>
</aside>
</section><section id="reproducibility-crisis" class="slide level2">
<h1>Reproducibility crisis</h1>
<ul>
<li>Not just psychology</li>
<li>“Hard” sciences, too</li>
<li>Data collection to statistical analysis to reporting to publishing</li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://cdn.shopify.com/s/files/1/0877/5762/products/Rigor_Mortis_1024x1024.jpg?v=1491240110" height=550px/></p>
</div>
<aside class="notes">
<p>Clearly, the significant or slight crisis in reproducibility extends across scientific domains. Indeed, the NPR science reporter Richard Harris in a book published earlier this year said that sloppy biomedical research creates worthless cures, crushes hope, costs billions. But rather than cast aspersions on other fields, let me own the sins of my own.</p>
</aside>
</section></section>
<section><section id="the-crisis-in-psychology" class="titleslide slide level1"><h1>The crisis in psychology</h1></section><section class="slide level2">

<div class="centered">
<p><img src="http://press.princeton.edu/images/k10970.gif" height=500px></p>
</div>
<aside class="notes">
<p>But rather than cast aspersions on other fields, let me focus on my own field’s deadly sins, as cognitive neuroscientist Chris Chambers put it.</p>
</aside>
</section><section id="the-sin-of-unreliability" class="slide level2">
<h1>The sin of unreliability</h1>
<div class="centered">
<p><img src="https://i.reddituploads.com/cfb6336d162f4b908cb6715d3da752b5?fit=max&h=1536&w=1536&s=cb3b9e51ea5fef6fdc229fb24b740b7d" height=500px></p>
</div>
</section><section id="studies-are-underpowered" class="slide level2">
<h1>Studies are underpowered</h1>
<div class="centered">
<p><img src="http://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.2000797.g003&type=large" height=500px></p>
<p><small>(<a href="http://doi.org/10.1371/journal.pbio.2000797">Szucs &amp; Ioannides, 2017</a>)</small></p>
</div>
<aside class="notes">
<p>As Szucs and Ioannides have shown based on an analysis of more than 10,000 papers in the cognitive neuroscience literature, sample sizes are small, and the probability of false negatives is high, especially for small to medium effect sizes.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<blockquote>
<p>“Assuming a realistic range of prior probabilities for null hypotheses, false report probability is likely to exceed 50% for the whole literature.”</p>
</blockquote>
<p><small>(<a href="http://doi.org/10.1371/journal.pbio.2000797">Szucs &amp; Ioannides, 2017</a>)</small></p>
</div>
<aside class="notes">
<p>So, this means that we may not know what we think we know.</p>
</aside>
</section><section id="the-sin-of-hoarding" class="slide level2">
<h1>The sin of hoarding…</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/wicherts_2006_amp_61_7_726_fig1a.jpg" height=500px></p>
<p><small>(<a href="http://doi.org/10.1037/0003-066X.61.7.726">Wicherts et al., 2006</a>)</small></p>
</div>
</section><section id="the-sin-of-corruptibility" class="slide level2">
<h1>The sin of corruptibility…</h1>
<div class="centered">
<p><a href="http://science.sciencemag.org/content/348/6239/1100.2"> <img src="https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/lacour-green.jpg" height=450px/> </a></p>
<p><small>(<a href="http://doi.org/10.1126/science.1256151">LaCour &amp; Green, 2014</a>)</small></p>
</div>
</section><section class="slide level2">

<div class="centered">
<p><a href="http://pubman.mpdl.mpg.de/pubman/item/escidoc:1569964:8/component/escidoc:1569966/Stapel_Investigation_Final_report.pdf"> <img src="https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/flawed-science-stapel.jpg" height=500px> </a></p>
</div>
<aside class="notes">
<ul>
<li>Stapel was Dean of the School of Social and Behavioral Sciences at Tilburg University, teacher of Scientific Ethics course</li>
<li>Fraud investigation launched when 3 grad students noticed anomalies – duplicate entries in data tables</li>
<li>Stapel confessed, lost position, gave up Ph.D., wrote a book</li>
</ul>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><a href="http://www.sciencemag.org/news/2012/09/harvard-psychology-researcher-committed-fraud-us-investigation-concludes"> <img src="https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/hauser-misconduct-science.jpg" height=550px> </a></p>
</div>
<aside class="notes">
<ul>
<li>Marc Hauser</li>
<li>Evolutionary/Comparative Psychologist, Professor at Harvard</li>
<li>Resigned 2011 after internal investigation found him responsible for research misconduct</li>
<li>Details see <a href="https://grants.nih.gov/grants/guide/notice-files/NOT-OD-12-149.html">2012 report by NIH Office of Research Integrity (ORI)</a> and <a href="http://archive.boston.com/whitecoatnotes/2012/09/05/marc-hauser-responds-federal-finding-scientific-misconduct/spzRWEVIPKA4BUu8wi8t8J/story.html">Hauser’s response</a>.</li>
</ul>
</aside>
</section><section id="the-sin-of-bias" class="slide level2">
<h1>The sin of bias…</h1>
<p>Bem, D.J. (2011). Experimental evidence for anomalous retroactive influences on cognition and affect. <em>Journal of Personality and Social Psychology</em>, <em>100</em>(3), 407-425.</p>
<blockquote>
<p>“This article reports 9 experiments, involving more than 1,000 participants, that test for retroactive influence by”time-reversing&quot; well-established psychological effects so that the individual’s responses are obtained before the putatively causal stimulus events occur.&quot;</p>
</blockquote>
<aside class="notes">
<p>And this 2011 paper by Daryl Bem from Cornell purporting to show evidence for Extrasensory Perception or precognition. Psychology is harder than physics, but it doesn’t supercede it. This paper as blogger Tal Yarkoni <a href="http://www.talyarkoni.org/blog/2011/01/10/the-psychology-of-parapsychology-or-why-good-researchers-publishing-good-articles-in-good-journals-can-still-get-it-totally-wrong/">notes</a> shows the perils of using standard, but flawed research practices.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://vignette.wikia.nocookie.net/45e9dc22-281b-41a5-93a7-f508a99b8722/scale-to-width-down/627" height=550></p>
</div>
<aside class="notes">
<p>Yes, Bem was arguing for some sort of “Minority Report”-like evidence for precognition or ESP.</p>
</aside>
</section><section class="slide level2">

<blockquote>
<p>“We argue that in order to convince a skeptical audience of a controversial claim, one needs to conduct strictly confirmatory studies and analyze the results with statistical tests that are conservative rather than liberal. We conclude that Bem’s <em>p</em> values do not indicate evidence in favor of precognition; instead, they indicate that experimental psychologists need to change the way they conduct their experiments and analyze their data.”</p>
</blockquote>
<p><small>(<a href="http://doi.org/10.1037/a0022790">Wagenmakers et al., 2011</a>)</small></p>
<aside class="notes">
<p>But a careful, post-publication re-evaluation showed that Bem had made a number of small, defensible given current practices, errors that accumulated across his paper. None of them were picked up in review.</p>
</aside>
</section><section id="the-sin-of-hurrying" class="slide level2">
<h1>The sin of hurrying…</h1>
<div class="centered">
<p><img src="https://static-content.springer.com/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig3_HTML.gif" height=550px></p>
</div>
<p><small>(<a href="http://doi.org/10.3758/s13428-015-0664-2">Nuijten et al., 2015</a>)</small></p>
<aside class="notes">
<p>Statistical reporting errors in the published literature are more common that many might think.</p>
</aside>
</section><section id="in-our-defense" class="slide level2">
<h1>In our defense…</h1>
</section><section id="behavior-multidimensional" class="slide level2">
<h1>Behavior multidimensional</h1>
<div class="centered">
<video data-autoplay height="550" controls>
<source src="https://nyu.databrary.org/slot/11652/307774,376273/asset/47075/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<p><small>(<a href="https://nyu.databrary.org/volume/232">Adolph et al., 2016</a>)</small></p>
</div>
</section><section id="embedded-in-networks" class="slide level2">
<h1>Embedded in networks</h1>
<div class="centered">
<p><img src="http://3.bp.blogspot.com/-3e_SbLI1Kbc/UkH085O8q5I/AAAAAAAACw4/lAZ_AJdzGss/s1600/bronfenbrenner.jpeg" height=500px></p>
</div>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.researchgate.net/profile/Carlo_Miniussi/publication/269877702/figure/fig2/AS:269128527249411@1441176649721/Hierarchical-modular-organisation-of-the-human-connectome-a-Hubs-regions-with-a.png" height=500px></p>
</div>
</section><section id="humans-are-diverse" class="slide level2">
<h1>Humans are diverse</h1>
<ul>
<li>But much (lab-based) data collected are from <strong>W</strong>estern, <strong>E</strong>ducated <strong>I</strong>ndustrialized, <strong>R</strong>ich, <strong>D</strong>emocratic (WEIRD) populations <a href="http://doi.org/10.1017/S0140525X0999152X">Henrich et al., 2010</a></li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://www.evoanth.net/wp-content/uploads/2014/12/psychologyweird.png" height=500px> </br> <small><a href="http://www.evoanth.net/2015/01/06/evolutionary-psychology-has-problems-and-it-isnt-getting-better/" class="uri">http://www.evoanth.net/2015/01/06/evolutionary-psychology-has-problems-and-it-isnt-getting-better/</a></small></p>
</div>
</section><section id="data-sensitive-harder-to-share" class="slide level2">
<h1>Data sensitive, hard(er) to share</h1>
<ul>
<li>Protect participant’s identities</li>
<li>Protect from harm/embarrassment</li>
<li>Anonymize (effective?) or get permission</li>
</ul>
</section><section id="psychology-is-harder-than-physics" class="slide level2">
<h1>Psychology is harder than physics</h1>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/psych-harder-1.jpg" width=800px/></p>
</div>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/psych-harder-2.jpg" width=800px/></p>
</div>
</section></section>
<section><section id="big-data-computation-in-psychological-science" class="titleslide slide level1"><h1>Big data computation in psychological science</h1></section><section id="mind-reading-in-fmri" class="slide level2">
<h1>“Mind-reading” in fMRI</h1>
<div class="centered">
<p><img src="http://ars.els-cdn.com/content/image/1-s2.0-S0960982211009377-gr1.jpg" height=500px> </br> <small>(<a href="https://doi.org/10.1016/j.cub.2011.08.031">Nishimoto et al., 2011</a>)</small></p>
</div>
</section><section class="slide level2">

<div id="htmlwidget-fb22304bcadb8009f6de" style="width:768px;height:576px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-fb22304bcadb8009f6de">{"x":{"diagram":"\n  digraph {\n\t  style=filled\n\t\tcolor=lightgrey\n\t\tnode [style=filled, color=lightblue]\n    template -> {regis}\n\t\tperson_i -> {sMRI, fMRI, survey, task, meta}\n    sMRI -> regis\n    regis -> fMRI\n    {survey, task} -> cleaning\n    {fMRI, cleaning, meta} -> indiv_analysis\n\t\t}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</section><section id="a-personal-example" class="slide level2">
<h1>A personal example</h1>
<ul>
<li>How does vision develop?</li>
<li><em>Experience</em>
<ul>
<li>Input +</li>
<li>Visually-guided action</li>
</ul></li>
<li><ul>
<li><em>Physical</em> (eye/brain/body) development</li>
</ul></li>
</ul>
</section><section id="measure-in-the-lab" class="slide level2">
<h1>Measure (in the lab)</h1>
<ul>
<li>Behavioral sensitivity</li>
<li>Brain responses</li>
<li>At different ages</li>
</ul>
</section><section class="slide level2">

<div class="centered">
<video data-autoplay loop height="550" controls>
<source src="https://nyu.databrary.org/slot/9825/-/asset/11645/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<p></br> <small> (<a href="http://doi.org/http://doi.org/10.17910/B7QG6W">Gilmore, 2014</a>) </small></p>
</div>
<aside class="notes">
<p>Using computer-generated displays like this.</p>
</aside>
</section><section id="childrens-behavior" class="slide level2 smaller">
<h1>Children’s behavior</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/moco-3-pattern-psychophysics/master/child-laminar-radial/img/child/p.corr.plot-1.png" height=500px></p>
<p><small> (<a href="http://doi.org/10.1167/15.12.1008">Adamiak et al., 2015</a>) </small></p>
</div>
</section><section id="adults-behavior" class="slide level2 smaller">
<h1>Adults’ behavior</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/moco-3-pattern-psychophysics/master/child-laminar-radial/img/adult/p.corr.plot-1.png" height=500px></p>
<p><small> (<a href="http://doi.org/10.1167/15.12.1008">Adamiak et al., 2015</a>) </small></p>
</div>
</section><section id="childrens-brain-responses" class="slide level2 smaller">
<h1>Children’s brain responses</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/gilmore-thomas-fesi-2015/master/figs/1F1/child/figX-channel-wise-effects-1.png" width="800px"> </br> <small>(<a href="https://doi.org/10.1371/journal.pone.0157911">Gilmore et al., 2015</a>)</small></p>
</div>
</section><section id="adults-brain-responses" class="slide level2">
<h1>Adults’ brain responses</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/gilmore-thomas-fesi-2015/master/figs/1F1/adult/figX-channel-wise-effects-1.png" width="800px"> </br> <small>(<a href="https://doi.org/10.1371/journal.pone.0157911">Gilmore et al., 2015</a>)</small></p>
</div>
</section><section id="but-whats-the-input-the-real-input" class="slide level2">
<h1>But, what’s the input? The <em>real</em> input?</h1>
</section><section class="slide level2">

<div class="centered">
<video data-autoplay height="550" controls>
<source src="https://nyu.databrary.org/slot/7740/0,24634/asset/16751/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<p></br> <small> (<a href="http://doi.org/10.17910/B7.116">Gilmore et al., 2015</a>) </small></p>
</div>
<aside class="notes">
<p>What if I had first-person, observer’s-eye views of what infants saw…</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<video data-autoplay height="550" controls>
<source src="https://nyu.databrary.org/slot/7740/0,24200/asset/16753/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<p></br> <small>(<a href="http://doi.org/10.17910/B7.116">Gilmore et al., 2015</a>)</small></p>
</div>
<aside class="notes">
<p>And what mothers’ saw while they moved together through the very same environment?</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/mom-baby-carrier.jpg" height=350px> </br> <small> (<a href="http://doi.org/10.17910/B7.123">Adolph, 2015</a>) </small></p>
</div>
</section><section class="slide level2">

<div id="htmlwidget-bceab1ac2683112701f2" style="width:768px;height:576px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-bceab1ac2683112701f2">{"x":{"diagram":"\n  digraph {\n\t  style=filled\n\t\tcolor=lightgrey\n\t\tnode [style=filled, color=lightblue]\n\t\t{mom_i, baby_i} -> video\n    video -> align_clip\n    align_clip -> ffmpeg\n    ffmpeg -> frame_seq\n    frame_seq -> {radial_filt, linear_filt, rot_filt}\n    {radial_filt, linear_filt, rot_filt} -> stats\n\t\t}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</section><section id="frame-by-frame-video-analysis" class="slide level2">
<h1>Frame-by-frame video analysis</h1>
<div class="centered">
<video data-autoplay height="550" controls>
<source src="https://nyu.databrary.org/slot/11680/0,24500/asset/41871/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<p><small> (<a href="http://doi.org/10.17910/B7988V">Jayaraman et al., 2015</a>) </small></p>
</div>
<aside class="notes">

</aside>
</section><section class="slide level2">

<div class="centered">
<video data-autoplay height="550" controls>
<source src="https://nyu.databrary.org/slot/11680/25500,50000/asset/41873/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
</div>
</section><section class="slide level2">

<div class="centered">
<video width="640" height="480" controls>
<source src="https://nyu.databrary.org/slot/11680/51000,75500/asset/41875/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
</div>
</section><section id="findings" class="slide level2 smaller">
<h1>Findings</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/optic-flow-locomotion.jpg" height=500px></p>
<p><small> (<a href="http://doi.org/10.1162/NECO_a_00645">Raudies &amp; Gilmore, 2014</a>) </small></p>
</div>
</section><section id="findings-1" class="slide level2">
<h1>Findings</h1>
<ul>
<li>Infant (passengers) experience faster visual speeds than mother</li>
<li>Controlling for speed of locomotion, environment</li>
<li>Motion “priors” for infants ≠ mothers</li>
</ul>
</section><section id="are-fast-flow-speeds-common" class="slide level2">
<h1>Are “fast” flow speeds common?</h1>
<div class="centered">
<video data-autoplay height="550" controls>
<source src="https://nyu.databrary.org/slot/11630/1567557,1747248/asset/39854/download?inline=true" type="video/mp4"> Your browser does not support the video tag.
</video>
<p><small> (<a href="http://doi.org/10.17910/B7988V%5D">Jayaraman et al., 2015</a>) </small></p>
</div>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/bloomington.jpg" width=400px> <img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/chennai.jpg" width=400px> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section class="slide level2">

<div class="centered">
<table>
<thead>
<tr class="header">
<th>Country</th>
<th>Females</th>
<th>Males</th>
<th>Age (wks)</th>
<th>Coded video Hrs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>India</td>
<td>17</td>
<td>13</td>
<td>3-63</td>
<td>3.1 (0.5-6.0)</td>
</tr>
<tr class="even">
<td>U.S.</td>
<td>15</td>
<td>19</td>
<td>4-62</td>
<td>4.6 (0.2-7.6)</td>
</tr>
</tbody>
</table>
<p></br> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section id="motion-speeds---6-weeks" class="slide level2 flexbox vcenter smaller">
<h1>Motion speeds - 6 weeks</h1>
<div class="centered">
<p>U.S. | India</br> <img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/006AP.png' width=400px> <img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/006MO.png' width=400px> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section id="motion-speeds-34-weeks" class="slide level2 flexbox vcenter smaller">
<h1>Motion speeds – 34 weeks</h1>
<div class="centered">
<p>U.S. | India</br><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/034JC.png' width=400px> <img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/034NW.png' width=400px> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section id="motion-speeds-58-weeks" class="slide level2 flexbox vcenter smaller">
<h1>Motion speeds – 58 weeks</h1>
<div class="centered">
<p>U.S. | India</br><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/057AP.png' width=400px/> <img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/058LA.png' width=400px/> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section id="linear-radial-patterns" class="slide level2 smaller">
<h1>Linear &gt; radial patterns</h1>
<div class="centered">
<p><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/pattern-correlations.jpg' height=450px/> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section id="simulating-developmental-change" class="slide level2 flexbox vcenter smaller">
<h1>Simulating developmental change</h1>
<div class="centered">
<p><small> <span class="math inline">\(\begin{pmatrix}\dot{x} \\ \dot{y}\end{pmatrix}=\frac{1}{z} \begin{pmatrix}-f &amp; 0 &amp; x\\ 0 &amp; -f &amp; y \end{pmatrix} \begin{pmatrix}{v_x{}}\\ {v_y{}} \\{v_z{}}\end{pmatrix}+ \frac{1}{f} \begin{pmatrix} xy &amp; -(f^2+x^2) &amp; fy\\ f^2+y^2 &amp; -xy &amp; -fy \end{pmatrix} \begin{pmatrix} \omega_{x}\\ \omega_{y}\\ \omega_{z} \end{pmatrix}\)</span> </small></p>
<p><strong>Geometry of environment/observer</strong>: <span class="math inline">\((x, y, z)\)</span></br> <strong>Translational speed</strong>: <span class="math inline">\((v_x, v_y, v_z)\)</span></br> <strong>Rotational speed</strong>: <span class="math inline">\((\omega_{x}, \omega_{y}, \omega{z})\)</span></br> <strong>Retinal flow</strong>: <span class="math inline">\((\dot{x}, \dot{y})\)</span></p>
</div>
</section><section id="parameters-for-simulation" class="slide level2">
<h1>Parameters For Simulation</h1>
<table>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Crawling Infant</th>
<th>Walking Infant</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eye height</td>
<td>0.30 m</td>
<td>0.60 m</td>
</tr>
<tr class="even">
<td>Locomotor speed</td>
<td>0.33 m/s</td>
<td>0.61 m/s</td>
</tr>
<tr class="odd">
<td>Head tilt</td>
<td>20 deg</td>
<td>9 deg</td>
</tr>
</tbody>
</table>
<div class="centered">
<p></br> <img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/kretch-etal.png" width=600px/> </br> <small> (<a href="http://dx.doi.org/10.1111/cdev.12206">Kretch et al., 2014</a>) </small></p>
</div>
</section><section class="slide level2">

<table>
<thead>
<tr class="header">
<th>Geometric Feature</th>
<th>Distance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Side wall</td>
<td>+/- 2 m</td>
</tr>
<tr class="even">
<td>Side wall height</td>
<td>2.5 m</td>
</tr>
<tr class="odd">
<td>Distance of ground plane</td>
<td>32 m</td>
</tr>
<tr class="even">
<td>Field of view width</td>
<td>60 deg</td>
</tr>
<tr class="odd">
<td>Field of view height</td>
<td>45 deg</td>
</tr>
</tbody>
</table>
</section><section id="simulating-flow-fields" class="slide level2 flexbox vcenter smaller">
<h1>Simulating Flow Fields</h1>
<div class="centered">
<p><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/simulation-flow-patterns.png' width=800px/> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section class="slide level2">

<div class="centered">
<p><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/simulation-flow-direction-hist.png' width=800px/> </br> <small> (<a href="http://doi.org/10.1109/DEVLRN.2015.7345450">Gilmore et al, 2015</a>) </small></p>
</div>
</section><section id="simulated-flow-speeds-ms" class="slide level2 flexbox vcenter">
<h1>Simulated Flow Speeds (m/s)</h1>
<div class="centered">
<table>
<thead>
<tr class="header">
<th>Type of Locomotion</th>
<th>Ground Plane</th>
<th>Room</th>
<th>Side Wall</th>
<th>Two Walls</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Crawling</td>
<td>14.41</td>
<td>14.42</td>
<td>14.43</td>
<td>14.62</td>
</tr>
<tr class="even">
<td>Walking</td>
<td>9.38</td>
<td>8.56</td>
<td>7.39</td>
<td>9.18</td>
</tr>
</tbody>
</table>
</div>
</section><section id="essentials-for-computationally-intensive-psychological-research" class="slide level2">
<h1>Essentials for computationally intensive psychological research</h1>
<ul>
<li class="fragment">Computational resources</li>
<li class="fragment">Technical expertise</li>
</ul>
</section><section id="create-reproducible-workflows" class="slide level2">
<h1>Create reproducible workflows</h1>
<p>Kitzes, J., Turek, D., &amp; Deniz, F. (Eds.). (2018). The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences. Oakland, CA: University of California Press. <a href="https://www.gitbook.com/book/bids/the-practice-of-reproducible-research/details">E-book</a>.</p>
</section><section id="share-materials-code-raw-data" class="slide level2">
<h1>Share materials, code, raw data</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/databrary.splash.jpg"
</br> <small><a href="http://databrary.org">databrary.org</a></small></p>
</div>
</section><section id="how-databrary-is-distinctive" class="slide level2">
<h1>How Databrary is distinctive</h1>
<ul>
<li>Open sharing among <em>authorized researchers</em>, not public</li>
<li>Share identifiable data <em>with permission</em></li>
<li>Store, search across, filter among participant &amp; session characteristics</li>
<li>Active (during study) curation reduces <em>post hoc</em> burden</li>
<li><a href="http://psyarxiv.com/kew8u">Gilmore, Kennedy, &amp; Adolph, 2017</a></li>
</ul>
</section><section id="what-ive-learned" class="slide level2">
<h1>What I’ve learned</h1>
</section><section id="barriers-to-reproducibility" class="slide level2">
<h1>Barriers to reproducibility</h1>
<ul>
<li>Technological</li>
<li>Cultural</li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://i.pinimg.com/originals/9b/f4/e5/9bf4e5a1d584bc6065c3e3231f9b3220.gif" height=550px></p>
</div>
</section><section class="slide level2">

<blockquote>
<p>“…psychologists tend to treat other peoples’ theories like toothbrushes; no self-respecting individual wants to use anyone else’s.”</p>
</blockquote>
<p><a href="https://www.psychologicalscience.org/observer/becoming-a-cumulative-science">Walter Mischel, 2009</a></p>
</section><section class="slide level2">

<blockquote>
<p>“Reviewers and editors want novel, interesting results. Why would I waste my time doing careful direct replications?”</p>
</blockquote>
<p>Any number of researchers I’ve talked with</p>
</section><section id="tools-empower" class="slide level2">
<h1>Tools empower</h1>
<ul>
<li><a href="http://rstudio.com">RStudio</a> &amp; <a href="http://jupyter.org">Project Jupyter</a> and literate programming</li>
<li>git, GitHub and version control</li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Rstudio.png/1200px-Rstudio.png" height=550px></p>
</div>
<aside class="notes">
<p>Here’s a depiction of the RStudio workspace. It is an integrated development environment for the R programming language.</p>
</aside>
</section><section class="slide level2">

<pre><code>## Joining multiple datasets

Fancy approach to multiple dataset merge. Joins datasets two at a time from left to right in the list. The result of a two-table join becomes the &#39;x&#39; dataset for the next join of a new dataset &#39;y&#39;.</code></pre>
<pre><code>```{r data-frame-demo}
df1 <- data.frame(id=1:10, x=rnorm(10), y=runif(10))
df2 <- data.frame(id=1:11, z=rnorm(11), a=runif(11))
df3 <- data.frame(id=2:10, b=rnorm(9), c=runif(9))

Reduce(function(...) { full_join(...) }, list(df1, df2, df3))
```</code></pre>
</section><section id="r-markdown" class="slide level2">
<h1>R Markdown</h1>
<ul>
<li>One document format
<ul>
<li>Text, images, movies, data plots, code (not just R), commentary, citations, equations</li>
</ul></li>
<li>Many outputs
<ul>
<li>HTML slides (like this one)</li>
<li>PDF, MS Word, Markdown documents, even full manuscripts!</li>
<li><a href="http://gilmore-lab.github.io">Web sites</a>, <a href="http://rick-gilmore.com">blogs</a></li>
<li><a href="http://bookdown.org">Books</a></li>
</ul></li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.dataquest.io/blog/images/jupyter/interface-screenshot.png" height=550px></p>
</div>
<aside class="notes">
<p>And here is the Jupyter notebook. It provides an interactive shell for python or other languages that allow text, images, and code to be integrated and interleaved.</p>
</aside>
</section><section id="next-generation-of-scientific-publishing" class="slide level2">
<h1>Next generation of scientific publishing</h1>
<ul>
<li>Lab notebooks that embody literate programming principles</li>
<li>Close links between data collection, cleaning, analysis, data repositories, preprints, publishers</li>
<li>Persistent identifiers for research materials, code, &amp; resources
<ul>
<li>All published figures, data tables, data sets, analysis code…</li>
</ul></li>
</ul>
</section></section>
<section><section id="lets-not-waste-a-good-crisis" class="titleslide slide level1"><h1>Let’s not waste a “good” crisis</h1></section><section class="slide level2">

<div class="centered">
<p><a href="http://www.nature.com/articles/s41562-016-0021/figures/1"> <img src="http://www.nature.com/article-assets/npg/nathumbehav/2017/s41562-016-0021/images_hires/w926/s41562-016-0021-f1.jpg" height=500px> </a> </br> <small> (<a href="http://doi.org/10.1038/s41562-016-0021">Munafo et al., 2017</a>) </small></p>
</div>
<aside class="notes">
<p>This recent manifesto from Nature Human Behavior describes the risks to reproducible science at every step of the process. I urge you to read it.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://previews.123rf.com/images/keng88/keng881302/keng88130200003/17772526-pile-of-collapsed-red-bricks-wall-Stock-Photo.jpg" height=550px></p>
</div>
<aside class="notes">
<p>If each data point is a brick, a cumulative science of behavior would take each one and turn it into…</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://i.pinimg.com/736x/43/41/c0/4341c08aa295923d8a679a12797bd6da--brick-architecture-amazing-architecture.jpg" height=550px></p>
</div>
<aside class="notes">
<p>beautiful, intricate structures of knowledge. So how do we build a cumulative science?</p>
</aside>
</section><section id="collect-share-video-as-data-and-documentation" class="slide level2">
<h1>Collect &amp; share video as data and documentation</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-video-reproducibility/master/img/gilmore-adolph-nat-hum-beh.jpg" height=550px></p>
</div>
<aside class="notes">
<p>Karen Adolph at NYU is my partner in founding and directing the Databrary project. We have argued that video plays a central role in improving reproducibility in behavioural science. It has uniquely powerful abilities to capture who said or did what when and in what context.</p>
</aside>
</section><section id="increase-sample-sizes" class="slide level2">
<h1>Increase sample sizes</h1>
<div class="centered">
<p><img src="https://s31.postimg.org/y9ygb9cd7/studyswap.jpg" height=500px></p>
</div>
<p>Or, <a href="https://christopherchartier.com/2017/08/26/building-a-cern-for-psychological-science/">“Building a CERN for Psychological Science”</a></p>
</section><section id="standardize-metadata" class="slide level2">
<h1>Standardize metadata</h1>
<ul>
<li>participants (age, gender, race/ethnicity, …)</li>
<li>settings (times, dates, places)</li>
<li>measures &amp; tasks</li>
</ul>
<div class="centered">
<p><img src="https://s3.amazonaws.com/blog.puzzlenation.com/official-uk-puzzle-club.jpg" height=350px></p>
</div>
</section><section id="improve-statistical-practices" class="slide level2">
<h1>Improve statistical practices</h1>
<ul>
<li>Automated checking of paper statistics (in American Psychological Association formats) via <a href="http://statcheck.io">Statcheck</a></li>
<li>Redefine “statistical significance” as <span class="math inline">\(p&lt;.005\)</span>? <a href="https://dx.doi.org/10.17605/OSF.IO/MKY9J">(Benjamin et al., 2017)</a></li>
<li>Or move away from <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">NHST</a> toward more robust and cumulative practices (Bayesian, CI/effect-size-driven)</li>
</ul>
</section><section id="store-data-materials-code-in-repositories" class="slide level2">
<h1>Store data, materials, code in repositories</h1>
<ul>
<li>Data libraries</li>
<li>Funder, journal mandates for sharing increasing</li>
<li>But no long-term, stable, funding sources for curation, archiving, sharing</li>
<li>ArXiv model
<ul>
<li>Institutional (Cornell) support</li>
<li>Subscription</li>
</ul></li>
</ul>
</section><section id="build-platforms-for-discovery" class="slide level2">
<h1>Build platforms for discovery</h1>
<ul>
<li>Data + analysis</li>
<li>e.g., PSU’s <a href="https://www.biostars.org/">Biostars</a></li>
</ul>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://farm9.staticflickr.com/8732/17059467232_8205574673_o.png" height=550px></p>
</div>
<aside class="notes">
<p>This is not pie in the sky. Let me tell you why.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/3/3f/HST-SM4.jpeg" height=550px></p>
</div>
</section><section class="slide level2">

<div class="centered">
<p><a href="https://en.wikipedia.org/wiki/Hubble_Ultra-Deep_Field"> <img src="https://upload.wikimedia.org/wikipedia/commons/6/69/NASA-HS201427a-HubbleUltraDeepField2014-20140603.jpg" height=550px> </a></p>
</div>
<aside class="notes">
<p>The Hubble Ultra Deep Field. Taken over 3.5 months in 2003-04. Contains an estimated 10,000 galaxies, and because time and space collapse at astronomical distances, looks back ~13 billion years, or 400-800 years before the big bang. So what would the Hubble telescope for human health and behavior look like?</p>
</aside>
</section><section id="data-from-diverse-domains" class="slide level2">
<h1>Data from diverse domains</h1>
<div class="centered">
<p><a href="http://www.thehumanproject.org"> <img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/thehumanproject.org.jpg" height=480px> </a></p>
</div>
</section><section class="slide level2">

<p><img src="http://images.samsung.com/is/image/samsung/p5/levant/smartphones/phones-for-every-need-001.png?$ORIGIN_PNG$" width=200px> <img src="https://images-na.ssl-images-amazon.com/images/I/71fea9jTevL._SX425_.jpg" width=200px> <img src="http://media.thelisttv.com/photo/2017/03/09/poster_e0d492c7bf0147d2b0d8b736efd6be9a_56564413_ver1.0_640_480.jpeg" width=200px></p>
</section><section id="link-measures-across-people" class="slide level2">
<h1>Link measures across people</h1>
<div class="centered">
<p><a href="http://www.openhumans.org"> <img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/openhumans.org.jpg" height=480px> </a></p>
</div>
</section><section id="web-based-data-visualization-analysis" class="slide level2">
<h1>Web-based data visualization, analysis</h1>
<div class="centered">
<video width="720" height="450" controls>
<source src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/mov/neurosynth-happy.mp4" type="video/mp4"> Your browser does not support the video tag.
</video>
</div>
</section><section class="slide level2">

<div class="centered">
<a href="http://www.socialexplorer.com/">
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/social-explorer.jpg" height=450px></p>
</div>
<p></a></p>
</div>
</section><section class="slide level2">

<div class="centered">
<video width="720" height="450" controls>
<source src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/mov/wordbank-vocabulary.mp4" type="video/mp4"> Your browser does not support the video tag.
</video>
</div>
</section><section id="search-filtering-by-personal-characteristics" class="slide level2">
<h1>Search, filtering by personal characteristics</h1>
<div class="centered">
<p><a href="http://ndar.nih.gov"> <img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/ndar.jpg" height=475px> </a></p>
</div>
</section><section id="curate-data-materials-as-they-are-generated" class="slide level2">
<h1>Curate data &amp; materials as they are generated</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/osf-io.jpg" height=500px/></p>
</div>
</section><section id="consistent-clear-sharing-permissions-structure" class="slide level2">
<h1>Consistent, clear sharing permissions structure</h1>
<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/databrary.splash.jpg" height=500px></p>
</div>
</section><section id="progress" class="slide level2">
<h1>Progress</h1>
<table>
<thead>
<tr class="header">
<th>Example</th>
<th>Multi-measure</th>
<th>Indiv link/search</th>
<th>Visualize</th>
<th>Self-curate</th>
<th>Permissions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Databrary</td>
<td>✔</td>
<td>✔</td>
<td>tabular</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr class="even">
<td>Human Proj</td>
<td>✔</td>
<td>✔</td>
<td>?</td>
<td>?</td>
<td>✔</td>
</tr>
<tr class="odd">
<td>ICPSR</td>
<td>✔</td>
<td>?</td>
<td>✔</td>
<td>?</td>
<td>✔</td>
</tr>
<tr class="even">
<td>Neurosynth</td>
<td>fMRI BOLD</td>
<td>group data</td>
<td>✔</td>
<td>public</td>
<td>NA</td>
</tr>
<tr class="odd">
<td>OpenNeuro</td>
<td>✔</td>
<td>?</td>
<td>✔</td>
<td>✔</td>
<td>public</td>
</tr>
<tr class="even">
<td>Open Humans</td>
<td>✔</td>
<td>✔</td>
<td>?</td>
<td>?</td>
<td>✔</td>
</tr>
<tr class="odd">
<td>OSF</td>
<td>✔</td>
<td></td>
<td></td>
<td>✔</td>
<td>public</td>
</tr>
<tr class="even">
<td>WordBank</td>
<td>M-CDI</td>
<td>group metadata</td>
<td>✔</td>
<td>?</td>
<td>public</td>
</tr>
</tbody>
</table>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAW9AAAAJDRhMTc5OGYyLWE4MzItNDNlOS1hMDJjLTllOGU2ZTNiNmMzNg.jpg" height=550px></p>
</div>
<aside class="notes">
<p>In closing, I’d like us to step outside of our narrow disciplinary silos.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://cdn2.hubspot.net/hub/134568/file-1208368053-jpg/6-blind-men-hans.jpg" height=550px></p>
</div>
<aside class="notes">
<p>To make the future of big data behavioral science one where we’re not just blind men studying our small part of the elephant.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="http://static.neatorama.com/images/2012-09/girl-hugging-elephant.jpg" height=550px></p>
</div>
<aside class="notes">
<p>But where we take off our opaque glasses and embrace the whole glorious animal.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.theclio.com/web/ul/19887.40334.jpg" height=550px></p>
</div>
<aside class="notes">
<p>Let’s build it here.</p>
</aside>
</section><section id="keep-in-touch" class="slide level2 vcenter flexbox">
<h1>Keep in touch</h1>
<h3 id="rogilmorepsu.edu"><a href="mailto:rogilmore@psu.edu">rogilmore@psu.edu</a></h3>
<h3 id="gilmore-lab.github.io"><a href="http://gilmore-lab-github.io">gilmore-lab.github.io</a></h3>
</section><section id="stack" class="slide level2">
<h1>Stack</h1>
<p>This talk was produced on 2017-09-07 in <a href="http://rstudio.com">RStudio Server Pro</a> using R Markdown and the reveal.JS framework on Penn State’s <a href="http://rstudio.aci.ics.psu.edu">ACI-ICS RStudio Server Pro instance</a>. The code and materials used to generate the slides may be found at <a href="https://github.com/gilmore-lab/aci-ics-2017-09-07/" class="uri">https://github.com/gilmore-lab/aci-ics-2017-09-07/</a>. Information about the R Session that produced the code is as follows:</p>
<pre><code>## R version 3.4.1 (2017-06-30)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Sierra 10.12.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] DiagrammeR_0.9.2 revealjs_0.9    
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_0.12.12       compiler_3.4.1     RColorBrewer_1.1-2
##  [4] influenceR_0.1.0   plyr_1.8.4         bindr_0.1         
##  [7] viridis_0.4.0      tools_3.4.1        digest_0.6.12     
## [10] jsonlite_1.5       viridisLite_0.2.0  gtable_0.2.0      
## [13] evaluate_0.10.1    tibble_1.3.3       rgexf_0.15.3      
## [16] pkgconfig_2.0.1    rlang_0.1.2        igraph_1.1.2      
## [19] rstudioapi_0.6     yaml_2.1.14        bindrcpp_0.2      
## [22] gridExtra_2.2.1    downloader_0.4     dplyr_0.7.2       
## [25] stringr_1.2.0      knitr_1.17         htmlwidgets_0.9   
## [28] hms_0.3            grid_3.4.1         rprojroot_1.2     
## [31] glue_1.1.1         R6_2.2.2           Rook_1.1-1        
## [34] XML_3.98-1.9       rmarkdown_1.6      ggplot2_2.2.1     
## [37] tidyr_0.6.3        purrr_0.2.3        readr_1.1.1       
## [40] magrittr_1.5       backports_1.1.0    scales_0.5.0      
## [43] htmltools_0.3.6    assertthat_0.2.0   colorspace_1.3-2  
## [46] brew_1.0-6         stringi_1.1.5      visNetwork_2.0.1  
## [49] lazyeval_0.2.0     munsell_0.4.3</code></pre>
</section></section>
    </div>
  </div>

  <script src="libs/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="libs/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: true,
        // Enables touch navigation on devices with touch input
        touch: true,
        // Opens links in an iframe preview overlay
        previewLinks: false,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
          { src: 'libs/reveal.js-3.3.0.1/plugin/notes/notes.js', async: true },
          { src: 'libs/reveal.js-3.3.0.1/plugin/zoom-js/zoom.js', async: true },
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
